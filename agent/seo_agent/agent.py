from urllib.parse import urlparse
import requests
import re
from agent.seo_agent.pojo import ProductInfo
from langgraph.prebuilt import create_react_agent
from agent.llm import create_azure_llm
from agent.seo_agent.prompt import GET_KEYWORDS_AGENT_PROMPT_TEMPLATE, CREATE_TITLE_AGENT_PROMPT_TEMPLATE
from agent.seo_agent.pojo import Keywords
# é‡‡ç”¨reAct

from agent.tool.tools import judge_if_brand, product_tavily_search


class GetKeywordsAgent():

    def __init__(self) -> None:
        self.llm = create_azure_llm()
        self.tool_list = [judge_if_brand, product_tavily_search]

    async def invoke(self, product_title: str, product_description: str, product_category: str) -> Keywords:
        prompt_template = GET_KEYWORDS_AGENT_PROMPT_TEMPLATE
        prompt = prompt_template.format(
            product_title=product_title, product_description=product_description, product_category=product_category)
        agent = create_react_agent(model=self.llm, tools=self.tool_list,
                                   prompt=prompt, response_format=Keywords)
        agent_result = await agent.ainvoke({})
        keywords: Keywords = agent_result["structured_response"]
        return keywords


class CreateTitleAgent():
    def __init__(self) -> None:
        self.llm = create_azure_llm()
        self.tool_list = [judge_if_brand, product_tavily_search]

    async def invoke(self, product_title: str, product_description: str, suggest: str, keywords: Keywords) -> ProductInfo:
        prompt_template = CREATE_TITLE_AGENT_PROMPT_TEMPLATE
        prompt = prompt_template.format(
            product_title=product_title, product_description=product_description, suggest=suggest, keywords=str(keywords))
        agent = create_react_agent(model=self.llm, tools=self.tool_list,
                                   prompt=prompt, response_format=ProductInfo)
        agent_result = await agent.ainvoke({})
        product_info: ProductInfo = agent_result["structured_response"]
        return product_info


# æ¥å…¥gradioçš„agent


class SEOAgent():
    def __init__(self, user_name) -> None:
        self.user_name = user_name

    def predict(self, user_question, chatbot):
        # å‡å¦‚len(chatbot)==1åˆ™ä¸ºç¬¬ä¸€æ¬¡å›å¤
        if len(chatbot) == 1:
            # ç¬¬ä¸€æ¬¡å›å¤
            # åˆ¤æ–­user_questionæ˜¯å¦ä¸ºé“¾æ¥ï¼Œä½¿ç”¨reæ¥è·å–é“¾æ¥éƒ¨åˆ†
            url_pattern = r'https?://(?:[-\w.])+(?:[:\d]+)?(?:/(?:[\w/_.])*(?:\?(?:[\w&=%.])*)?(?:#(?:[\w.])*)?)?'
            urls = re.findall(url_pattern, user_question)

            if urls:
                # å¦‚æœåŒ…å«é“¾æ¥ï¼Œè¿›è¡ŒSEOåˆ†æ
                url = urls[0]
                return self.analyze_seo(url)
            else:
                # å¦‚æœä¸åŒ…å«é“¾æ¥ï¼Œæä¾›SEOå»ºè®®
                return self.provide_seo_advice(user_question)
        else:
            # éç¬¬ä¸€æ¬¡å›å¤
            return self.handle_follow_up(user_question, chatbot)

    def analyze_seo(self, url):
        """åˆ†æURLçš„SEOæƒ…å†µ"""
        try:
            response = requests.get(url, timeout=10)
            content = response.text

            # åŸºæœ¬çš„SEOæ£€æŸ¥
            seo_analysis = []

            # æ£€æŸ¥æ ‡é¢˜
            title_match = re.search(
                r'<title>(.*?)</title>', content, re.IGNORECASE)
            if title_match:
                title = title_match.group(1)
                seo_analysis.append(f"âœ… é¡µé¢æ ‡é¢˜: {title}")
                if len(title) < 30:
                    seo_analysis.append("âš ï¸ æ ‡é¢˜å¯èƒ½è¿‡çŸ­ï¼Œå»ºè®®30-60å­—ç¬¦")
                elif len(title) > 60:
                    seo_analysis.append("âš ï¸ æ ‡é¢˜å¯èƒ½è¿‡é•¿ï¼Œå»ºè®®30-60å­—ç¬¦")
            else:
                seo_analysis.append("âŒ æœªæ‰¾åˆ°é¡µé¢æ ‡é¢˜")

            # æ£€æŸ¥metaæè¿°
            meta_desc_match = re.search(
                r'<meta[^>]*name=["\']description["\'][^>]*content=["\']([^"\']*)["\']', content, re.IGNORECASE)
            if meta_desc_match:
                meta_desc = meta_desc_match.group(1)
                seo_analysis.append(f"âœ… Metaæè¿°: {meta_desc}")
                if len(meta_desc) < 120:
                    seo_analysis.append("âš ï¸ Metaæè¿°å¯èƒ½è¿‡çŸ­ï¼Œå»ºè®®120-160å­—ç¬¦")
                elif len(meta_desc) > 160:
                    seo_analysis.append("âš ï¸ Metaæè¿°å¯èƒ½è¿‡é•¿ï¼Œå»ºè®®120-160å­—ç¬¦")
            else:
                seo_analysis.append("âŒ æœªæ‰¾åˆ°Metaæè¿°")

            # æ£€æŸ¥H1æ ‡ç­¾
            h1_count = len(re.findall(
                r'<h1[^>]*>.*?</h1>', content, re.IGNORECASE))
            if h1_count == 1:
                seo_analysis.append("âœ… é¡µé¢æœ‰ä¸”ä»…æœ‰ä¸€ä¸ªH1æ ‡ç­¾")
            elif h1_count == 0:
                seo_analysis.append("âŒ é¡µé¢ç¼ºå°‘H1æ ‡ç­¾")
            else:
                seo_analysis.append(f"âš ï¸ é¡µé¢æœ‰{h1_count}ä¸ªH1æ ‡ç­¾ï¼Œå»ºè®®åªæœ‰ä¸€ä¸ª")

            # æ£€æŸ¥å›¾ç‰‡altå±æ€§
            img_tags = re.findall(r'<img[^>]*>', content, re.IGNORECASE)
            img_with_alt = len(re.findall(
                r'<img[^>]*alt=["\'][^"\']*["\'][^>]*>', content, re.IGNORECASE))
            if img_tags:
                alt_percentage = (img_with_alt / len(img_tags)) * 100
                seo_analysis.append(f"ğŸ“Š å›¾ç‰‡altå±æ€§è¦†ç›–ç‡: {alt_percentage:.1f}% ({
                                    img_with_alt}/{len(img_tags)})")
                if alt_percentage < 80:
                    seo_analysis.append("âš ï¸ å»ºè®®ä¸ºæ‰€æœ‰å›¾ç‰‡æ·»åŠ altå±æ€§")

            return "\n".join(seo_analysis)

        except Exception as e:
            return f"âŒ åˆ†æå¤±è´¥: {str(e)}"

    def provide_seo_advice(self, question):
        """æä¾›SEOå»ºè®®"""
        advice = [
            "ğŸ” SEOä¼˜åŒ–å»ºè®®ï¼š",
            "",
            "1. **å…³é”®è¯ä¼˜åŒ–**",
            "   - åœ¨æ ‡é¢˜ã€æè¿°ã€å†…å®¹ä¸­åˆç†ä½¿ç”¨å…³é”®è¯",
            "   - é¿å…å…³é”®è¯å †ç Œ",
            "",
            "2. **å†…å®¹è´¨é‡**",
            "   - æä¾›æœ‰ä»·å€¼ã€åŸåˆ›çš„å†…å®¹",
            "   - ä¿æŒå†…å®¹æ›´æ–°é¢‘ç‡",
            "",
            "3. **æŠ€æœ¯SEO**",
            "   - ç¡®ä¿ç½‘ç«™åŠ è½½é€Ÿåº¦å¿«",
            "   - ä¼˜åŒ–ç§»åŠ¨ç«¯ä½“éªŒ",
            "   - ä½¿ç”¨HTTPSåè®®",
            "",
            "4. **ç”¨æˆ·ä½“éªŒ**",
            "   - æ¸…æ™°çš„ç½‘ç«™ç»“æ„",
            "   - æ˜“äºå¯¼èˆª",
            "   - å‡å°‘è·³å‡ºç‡",
            "",
            "è¯·æä¾›å…·ä½“ç½‘å€ï¼Œæˆ‘å¯ä»¥ä¸ºæ‚¨è¿›è¡Œè¯¦ç»†çš„SEOåˆ†æï¼"
        ]
        return "\n".join(advice)

    def handle_follow_up(self, user_question, chatbot):
        """å¤„ç†åç»­å¯¹è¯"""
        # ç®€å•çš„å¯¹è¯å¤„ç†é€»è¾‘
        if "è°¢è°¢" in user_question or "æ„Ÿè°¢" in user_question:
            return "ä¸å®¢æ°”ï¼å¦‚æœæ‚¨è¿˜æœ‰å…¶ä»–SEOç›¸å…³é—®é¢˜ï¼Œéšæ—¶å¯ä»¥é—®æˆ‘ã€‚"
        elif "å¸®åŠ©" in user_question or "æ€ä¹ˆ" in user_question:
            return "æˆ‘å¯ä»¥å¸®æ‚¨ï¼š\n1. åˆ†æç½‘ç«™SEOæƒ…å†µ\n2. æä¾›SEOä¼˜åŒ–å»ºè®®\n3. è§£ç­”SEOç›¸å…³é—®é¢˜\n\nè¯·æä¾›ç½‘å€æˆ–å…·ä½“é—®é¢˜ï¼"
        else:
            return "æˆ‘ç†è§£æ‚¨çš„é—®é¢˜ã€‚ä¸ºäº†æ›´å¥½åœ°å¸®åŠ©æ‚¨ï¼Œè¯·æä¾›å…·ä½“çš„ç½‘å€æˆ–æ›´è¯¦ç»†çš„é—®é¢˜æè¿°ã€‚"
