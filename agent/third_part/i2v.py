      
from agent.third_part.prompt import ANALYSE_IMAGE_VEO3_PROMPT_MODEL_SHOW_en, ANALYSE_IMAGE_VEO3_PROMPT_MODEL_WALK_en, ANALYSE_IMAGE_VEO3_PROMPT_MODEL_SHOW_WITH_SUGGESTION_en, ANALYSE_IMAGE_VEO3_PROMPT_MODEL_WALK_WITH_SUGGESTION_en, ANALYSE_IMAGE_KLING_PROMPT_MODEL_STAND_SHOW_en, ANALYSE_IMAGE_KLING_PROMPT_MODEL_CAT_WALK_en, ANALYSE_IMAGE_KLING_PROMPT_MODEL_STAND_SHOW_WITH_SUGGESTION_en, ANALYSE_IMAGE_KLING_PROMPT_MODEL_CAT_WALK_WITH_SUGGESTION_en, ANALYSE_IMAGE_RESPONSE_SCHEMA, ANALYSE_IMAGE_HUMAN_PROMPT_en, ANALYSE_IMAGE_HUMAN_PROMPT_WITH_SUGGESTION_en, MODIFY_KLING_PROMPT_WITH_SUGGESTION_en, MODIFY_PROMPT_WITH_SUGGESTION_en
import mimetypes
import json
from vertexai.generative_models import Part
from agent.llm import get_gemini_multimodal_model
from agent.utils import get_url_data
import os
from abc import abstractmethod, ABC
from typing import List
import httpx
import uuid
import time
import asyncio
from config import conf
from config import logger
from google.genai import types
from agent.third_part.aliyunoss import share_file_in_oss
from google import genai
from moviepy.editor import VideoFileClip
import mimetypes
from agent.mini_agent import ActionTypesClassifier
from typing import Literal
action_types = [
    "æ¨¡ç‰¹å±•ç¤ºè¡£æœ",
    "æ¨¡ç‰¹èµ°ç§€",
    "æ¨¡ç‰¹è½¬èº«",
    "æ¨¡ç‰¹è°ƒæ•´è¡£æœ",
    "æ¨¡ç‰¹ç”¨æ‰‹æŠšæ‘¸è¡£æœ",
    "æ¨¡ç‰¹æèµ·è£™å­"
]

class CreateVideoError(Exception):
    def __init__(self, message: str):
        self.message = message
        super().__init__(self.message)


class I2VStrategy(ABC):
    def __init__(self, name: str):
        self.name = name

    @abstractmethod
    def generate_video_prompt(self, product, product_info, img_path, img_info, duration: int, action_type: str = "model_show"):
        """ç”Ÿæˆè§†é¢‘æç¤ºè¯
        product: å•†å“åç§°
        product_info: å•†å“ä¿¡æ¯
        img_path: æ¨¡ç‰¹å›¾ç‰‡è·¯å¾„
        img_info: æ¨¡ç‰¹å›¾ç‰‡ä¿¡æ¯
        duration: è§†é¢‘æ—¶é•¿
        type: è§†é¢‘ç±»å‹ï¼ˆmodel_show, model_walk
        return: è§†é¢‘æç¤ºè¯
        """
        raise NotImplementedError(
            "generate_video_prompt method must be implemented")

    @abstractmethod
    def generate_video_prompt_with_suggestion(self, product, product_info, img_path, img_info, duration: int, suggestion: str, action_type: str = "model_show"):
        """
        æ ¹æ®suggestionç”Ÿæˆè§†é¢‘æç¤ºè¯
        """
        raise NotImplementedError(
            "generate_video_prompt_with_suggestion method must be implemented")

    @abstractmethod
    async def execute_generate_video(self, img_path, positive_prompt: str, negative_prompt: str,  duration: int) -> str:
        """æ‰§è¡Œç­–ç•¥çš„é€»è¾‘
        img_path: æ¨¡ç‰¹å›¾ç‰‡è·¯å¾„
        positive_prompt: è§†é¢‘æç¤ºè¯
        negative_prompt: è§†é¢‘è´Ÿå‘æç¤ºè¯
        duration: è§†é¢‘æ—¶é•¿
        return: è§†é¢‘url
        """
        raise NotImplementedError("execute method must be implemented")


class I2VStrategyChain:
    def __init__(self, strategies: List[I2VStrategy]):
        self.strategies = strategies

    def get_strategy(self, i2v_strategy: str):
        """
        æ ¹æ®ç­–ç•¥åç§°è·å–ç­–ç•¥
        """
        for strategy in self.strategies:
            if strategy.name == i2v_strategy:
                return strategy
        raise Exception(f"ä¸æ”¯æŒçš„ç­–ç•¥: {i2v_strategy}")

    async def execute_chain_with_prompt(self, img_path, video_positive_prompt: str, video_negative_prompt: str, duration: int, resolution: dict = {},  i2v_strategy: str = "keling"):
        strategy = self.get_strategy(i2v_strategy)
        video_url = await strategy.execute_generate_video(
            img_path=img_path, positive_prompt=video_positive_prompt, negative_prompt=video_negative_prompt, duration=duration)
        return video_url

    async def execute_chain_with_suggestion(self, product, product_info, img_path, img_info, duration: int, resolution: dict = {}, action_type: str = "model_show", suggestion: str = "", i2v_strategy: str = "keling"):
        """
        è¿”å›è§†é¢‘æç¤ºè¯ï¼Œè§†é¢‘è´Ÿå‘æç¤ºè¯ï¼Œè§†é¢‘url
        """
        strategy = self.get_strategy(i2v_strategy)
        video_positive_prompt, video_negative_prompt = strategy.generate_video_prompt_with_suggestion(
            product, product_info, img_path, img_info, duration, suggestion, action_type=action_type)
        video_url = await strategy.execute_generate_video(
            img_path, video_positive_prompt, video_negative_prompt, duration)
        return video_positive_prompt, video_negative_prompt, video_url

    async def execute_chain(self, product, product_info, img_path, img_info, duration: int, resolution: dict = {}, action_type: str = "model_show", i2v_strategy: str = "keling"):
        """
        è¿”å›è§†é¢‘æç¤ºè¯ï¼Œè§†é¢‘è´Ÿå‘æç¤ºè¯ï¼Œè§†é¢‘url(urlæ˜¯global url)
        """
        strategy = self.get_strategy(i2v_strategy)
        video_positive_prompt, video_negative_prompt = strategy.generate_video_prompt(
            product, product_info, img_path, img_info, duration, action_type=action_type)
        video_url = await strategy.execute_generate_video(
            img_path, video_positive_prompt, video_negative_prompt, duration)
        return video_positive_prompt, video_negative_prompt, video_url

    async def execute_chain_with_prompt(self, img_path, video_positive_prompt: str, video_negative_prompt: str, duration: int, resolution: dict = {},  i2v_strategy: str = "keling"):
        strategy = self.get_strategy(i2v_strategy)
        video_url = await strategy.execute_generate_video(
            img_path=img_path, positive_prompt=video_positive_prompt, negative_prompt=video_negative_prompt, duration=duration)
        return video_url

KELING_STRATEGY = "keling"
class Keling(I2VStrategy):
    def __init__(self, model: str = "kling-v2-1"):
        name: str = "keling"
        self.model = model
        super().__init__(name)

    def generate_video_prompt(self, product, product_info, img_path, img_info, duration: int, action_type: str = "æ¨¡ç‰¹å±•ç¤ºè¡£æœ"):
        classifier = ActionTypesClassifier(
            categories=["æ¨¡ç‰¹å±•ç¤ºè¡£æœ", "æ¨¡ç‰¹èµ°ç§€", "æ¨¡ç‰¹è½¬èº«", "æ¨¡ç‰¹è°ƒæ•´è¡£æœ", "æ¨¡ç‰¹ç”¨æ‰‹æŠšæ‘¸è¡£æœ", "æ¨¡ç‰¹æèµ·è£™å­","ä»¥ä¸Šéƒ½ä¸åŒ¹é…"])
        category = classifier.classify(action_type)
        
        with open(img_path, "rb") as file:
            image_data = file.read()
        mime_type, _ = mimetypes.guess_type(img_path)
        if mime_type is None:
            mime_type = "image/jpeg"
        if category == "æ¨¡ç‰¹å±•ç¤ºè¡£æœ":
            ANALYSE_IMAGE_SYSTEM_PROMPT_en = ANALYSE_IMAGE_KLING_PROMPT_MODEL_STAND_SHOW_en
            video_negative_prompt = "deformation, poor composition, camera movement, model walking, appearance of other people or loss of facial or limb structure such as bad teeth, bad eyes, bad limbs."
        elif category == "æ¨¡ç‰¹èµ°ç§€":
            ANALYSE_IMAGE_SYSTEM_PROMPT_en = ANALYSE_IMAGE_KLING_PROMPT_MODEL_CAT_WALK_en
            video_negative_prompt = "deformation, poor composition, model standing still, appearance of other people or loss of facial or limb structure such as bad teeth, bad eyes, bad limbs."
        elif category == "æ¨¡ç‰¹è½¬èº«":
            video_positive_prompt = "The model stands tall in a neutral pose and begins to turn gracefully in place, rotating her body in a slow full circle. As she turns, the fabric of the clothing subtly flares and sways, revealing the outfit from all angles. The motion is smooth and elegant, highlighting the texture and fit of the garment in motion."
            video_negative_prompt = "deformation, poor composition, model standing still, appearance of other people or loss of facial or limb structure such as bad teeth, bad eyes, bad limbs."
            return video_positive_prompt, video_negative_prompt
        elif category == "æ¨¡ç‰¹è°ƒæ•´è¡£æœ":
            video_positive_prompt = "The model stands still in a relaxed posture, using one hand to gently smooth the front of the outfit and subtly adjust the sleeves, collar, or hemline. These refined movements emphasize the fit and texture of the garment, conveying a sense of attention to detail and elegance."
            video_negative_prompt = "deformation, poor composition, camera movement, model walking, appearance of other people or loss of facial or limb structure such as bad teeth, bad eyes, bad limbs."
            return video_positive_prompt, video_negative_prompt
        elif category == "æ¨¡ç‰¹ç”¨æ‰‹æŠšæ‘¸è¡£æœ":
            video_positive_prompt = "The model stands still in an elegant pose, gently raising one hand and slowly gliding it along the contour of the garment to subtly guide attention to its shape and craftsmanship. The movement is smooth and expressive, enhancing the visual appeal of the fabric."
            video_negative_prompt = "deformation, poor composition, camera movement, model walking, appearance of other people or loss of facial or limb structure such as bad teeth, bad eyes, bad limbs."
            return video_positive_prompt, video_negative_prompt
        elif category == "æ¨¡ç‰¹æèµ·è£™å­":
            video_positive_prompt = "The model stands gracefully in place and gently lifts both sides of the skirt slightly with her hands, holding the fabric momentarily to reveal its soft drape and inner lining. She then slowly lowers the skirt back into place, allowing it to fall naturally and smoothly. This fluid motion emphasizes the skirtâ€™s volume, texture, and elegance while keeping the overall posture composed and refined."
            video_negative_prompt = "deformation, poor composition, camera movement, model walking, appearance of other people or loss of facial or limb structure such as bad teeth, bad eyes, bad limbs."
            return video_positive_prompt, video_negative_prompt
        else:
            # "ä»¥ä¸Šéƒ½ä¸åŒ¹é…"
            video_positive_prompt = action_type
            video_negative_prompt = "deformation, poor composition, camera movement, model walking, appearance of other people or loss of facial or limb structure such as bad teeth, bad eyes, bad limbs."
            return video_positive_prompt, video_negative_prompt
        gemini_generative_model = get_gemini_multimodal_model(
            system_prompt=ANALYSE_IMAGE_SYSTEM_PROMPT_en,
            response_schema=ANALYSE_IMAGE_RESPONSE_SCHEMA)
        response = gemini_generative_model.generate_content(
            [
                ANALYSE_IMAGE_HUMAN_PROMPT_en.format(
                    product=product, product_info=product_info, img_info=img_info, duration=duration),
                Part.from_data(image_data, mime_type=mime_type)
            ]
        )
        content = response.candidates[0].content.parts[0].text
        content_json = json.loads(content)
        video_positive_prompt = content_json.get("prompt", "")
        return video_positive_prompt, video_negative_prompt

    def generate_video_prompt_with_suggestion(self, product, product_info, img_path, img_info, duration: int, suggestion: str = "", action_type: str = "æ¨¡ç‰¹å±•ç¤ºè¡£æœ"):
        classifier = ActionTypesClassifier(
            categories=["æ¨¡ç‰¹å±•ç¤ºè¡£æœ", "æ¨¡ç‰¹èµ°ç§€", "æ¨¡ç‰¹è½¬èº«", "æ¨¡ç‰¹è°ƒæ•´è¡£æœ", "æ¨¡ç‰¹ç”¨æ‰‹æŠšæ‘¸è¡£æœ", "æ¨¡ç‰¹æèµ·è£™å­"])
        category = classifier.classify(action_type+" "+ suggestion)

        with open(img_path, "rb") as file:
            image_data = file.read()
        mime_type, _ = mimetypes.guess_type(img_path)
        if mime_type is None:
            mime_type = "image/jpeg"
        if category == "æ¨¡ç‰¹å±•ç¤ºè¡£æœ" or category == "æ¨¡ç‰¹èµ°ç§€":
            if category == "æ¨¡ç‰¹å±•ç¤ºè¡£æœ":
                ANALYSE_IMAGE_SYSTEM_PROMPT_en = ANALYSE_IMAGE_KLING_PROMPT_MODEL_STAND_SHOW_WITH_SUGGESTION_en
                video_negative_prompt = "deformation, poor composition, camera movement, model walking, appearance of other people or loss of facial or limb structure such as bad teeth, bad eyes, bad limbs."
            elif category == "æ¨¡ç‰¹èµ°ç§€":
                ANALYSE_IMAGE_SYSTEM_PROMPT_en = ANALYSE_IMAGE_KLING_PROMPT_MODEL_CAT_WALK_WITH_SUGGESTION_en
                video_negative_prompt = "deformation, poor composition, model standing still, appearance of other people or loss of facial or limb structure such as bad teeth, bad eyes, bad limbs."
            gemini_generative_model = get_gemini_multimodal_model(
                system_prompt=ANALYSE_IMAGE_SYSTEM_PROMPT_en,
                response_schema=ANALYSE_IMAGE_RESPONSE_SCHEMA)
            response = gemini_generative_model.generate_content(
                [
                    ANALYSE_IMAGE_HUMAN_PROMPT_WITH_SUGGESTION_en.format(
                        product=product, product_info=product_info, img_info=img_info, duration=duration, user_suggestion=suggestion),
                    Part.from_data(image_data, mime_type=mime_type)
                ]
            )
        else:
            if category == "æ¨¡ç‰¹è½¬èº«":
                video_positive_prompt = "The model stands tall in a neutral pose and begins to turn gracefully in place, rotating her body in a slow full circle. As she turns, the fabric of the clothing subtly flares and sways, revealing the outfit from all angles. The motion is smooth and elegant, highlighting the texture and fit of the garment in motion."
                video_negative_prompt = "deformation, poor composition, model standing still, appearance of other people or loss of facial or limb structure such as bad teeth, bad eyes, bad limbs."
            elif category == "æ¨¡ç‰¹è°ƒæ•´è¡£æœ":
                video_positive_prompt = "The model stands still in a relaxed posture, using one hand to gently smooth the front of the outfit and subtly adjust the sleeves, collar, or hemline. These refined movements emphasize the fit and texture of the garment, conveying a sense of attention to detail and elegance."
                video_negative_prompt = "deformation, poor composition, camera movement, model walking, appearance of other people or loss of facial or limb structure such as bad teeth, bad eyes, bad limbs."
            elif category == "æ¨¡ç‰¹ç”¨æ‰‹æŠšæ‘¸è¡£æœ":
                video_positive_prompt = "The model stands still in an elegant pose, gently raising one hand and slowly gliding it along the contour of the garment to subtly guide attention to its shape and craftsmanship. The movement is smooth and expressive, enhancing the visual appeal of the fabric."
                video_negative_prompt = "deformation, poor composition, camera movement, model walking, appearance of other people or loss of facial or limb structure such as bad teeth, bad eyes, bad limbs."
            elif category == "æ¨¡ç‰¹æèµ·è£™å­":
                video_positive_prompt = "The model stands gracefully in place and gently lifts both sides of the skirt slightly with her hands, holding the fabric momentarily to reveal its soft drape and inner lining. She then slowly lowers the skirt back into place, allowing it to fall naturally and smoothly. This fluid motion emphasizes the skirtâ€™s volume, texture, and elegance while keeping the overall posture composed and refined."
                video_negative_prompt = "deformation, poor composition, camera movement, model walking, appearance of other people or loss of facial or limb structure such as bad teeth, bad eyes, bad limbs."
            gemini_generative_model = get_gemini_multimodal_model(
                system_prompt=MODIFY_KLING_PROMPT_WITH_SUGGESTION_en,
                response_schema=ANALYSE_IMAGE_RESPONSE_SCHEMA)
            response = gemini_generative_model.generate_content(
                [
                    MODIFY_PROMPT_WITH_SUGGESTION_en.format(
                        video_positive_prompt=video_positive_prompt, user_suggestion=suggestion),
                ]
            )
        content = response.candidates[0].content.parts[0].text
        content_json = json.loads(content)
        video_positive_prompt = content_json.get("prompt", "")
        return video_positive_prompt, video_negative_prompt

    async def execute_generate_video(self, img_path, positive_prompt: str, negative_prompt: str,  duration: Literal[5, 10]) -> str:
        # ä½¿ç”¨kelingçš„apiç”Ÿæˆè§†é¢‘ï¼Œæœ€ç»ˆè¿”å›ä¸€ä¸ªurlï¼Œurlæ˜¯è§†é¢‘çš„åœ°å€
        http_client = httpx.Client(timeout=httpx.Timeout(
            600.0, connect=60.0), follow_redirects=True)
        KLING_API_KEY = conf.get("KLING_API_KEY")
        KLING_SECRET = conf.get("KLING_SECRET")
        KLING_API_BASE_URL = conf.get("KLING_API_BASE_URL")
        image_url = share_file_in_oss(img_path, f"{uuid.uuid4()}.jpg")
        payload = {
            # kling-v1, kling-v1-5, kling-v1-6, kling-v2-master, kling-v2-1, kling-v2-1-master
            "model": self.model,
            "mode": "pro",  # std æ ‡å‡†ï¼Œpro å¢å¼º
            "image": image_url,
            "prompt": positive_prompt,
            "negative_prompt": negative_prompt,
            "duration": duration  # æšä¸¾å€¼ï¼š5ï¼Œ10
        }

        headers = {
            "X-API-Key": KLING_API_KEY,
            "X-Secret-Key": KLING_SECRET,
            "Content-Type": "application/json",
        }
        url = f"{KLING_API_BASE_URL}/gen_video_task_by_image_create"

        response = http_client.post(url, headers=headers, json=payload)
        response = response.json()
        task_id = response["data"]["taskId"]

        headers = {
            "X-API-Key": KLING_API_KEY,
            "X-Secret-Key": KLING_SECRET,
            "Content-Type": "application/json",
        }
        url = f"{KLING_API_BASE_URL}/gen_video_task_by_image_get/{task_id}"
        interval = 30  # æ¯30ç§’æ£€æŸ¥ä¸€æ¬¡ä»»åŠ¡çŠ¶æ€
        start_time = time.time()
        max_wait = 600  # æœ€é•¿ç­‰å¾…æ—¶é—´10åˆ†é’Ÿ

        while True:
            try:
                response = http_client.get(url, headers=headers)
                response.raise_for_status()
                data = response.json()
            except httpx.RequestError as e:
                logger.error(f"è¯·æ±‚å¼‚å¸¸: {type(e).__name__}: {e}")
                raise Exception(f"è¯·æ±‚å¼‚å¸¸: {type(e).__name__}: {e}")
            except httpx.HTTPStatusError as e:
                logger.error(f"è¯·æ±‚å¤±è´¥ï¼ŒçŠ¶æ€ç ï¼š{e.response.status_code}")
                raise CreateVideoError(f"è¯·æ±‚å¤±è´¥ï¼ŒçŠ¶æ€ç ï¼š{e.response.status_code}")
            except Exception as e:
                logger.error(f"è§£æå“åº”å¤±è´¥: {e}")
                raise CreateVideoError(f"è§£æå“åº”å¤±è´¥: {e}")
            task_status = data.get("task_status")
            if time.time() - start_time > max_wait:
                logger.error("ç­‰å¾…è¶…æ—¶ï¼Œä»»åŠ¡æœªå®Œæˆã€‚")
                raise CreateVideoError("ç­‰å¾…è¶…æ—¶ï¼Œä»»åŠ¡æœªå®Œæˆã€‚")

            if task_status == "processing":
                logger.info("è§†é¢‘æ­£åœ¨å¤„ç†ä¸­ï¼Œç»§ç»­ç­‰å¾…...")
            elif task_status == "submitted":
                logger.info("ä»»åŠ¡å·²æäº¤ï¼Œç­‰å¾…å¤„ç†...")
            elif task_status == "succeed":
                video_list = data.get("videos", [])
                if video_list:
                    url = video_list[0].get("url")
                    if url:
                        return url
                    else:
                        logger.error("è§†é¢‘ç»“æœä¸ºç©ºã€‚")
                        raise CreateVideoError("è§†é¢‘ç»“æœä¸ºç©ºã€‚")
                else:
                    logger.error("è§†é¢‘ç»“æœä¸ºç©ºã€‚")
                    raise CreateVideoError("è§†é¢‘ç»“æœä¸ºç©ºã€‚")
            elif task_status == "failed":
                logger.error("ä»»åŠ¡å¤±è´¥ï¼Œæ— æ³•è·å–è§†é¢‘ã€‚")
                raise CreateVideoError("ä»»åŠ¡å¤±è´¥ï¼Œæ— æ³•è·å–è§†é¢‘ã€‚")
            else:
                logger.error(f"æœªçŸ¥ä»»åŠ¡çŠ¶æ€: {task_status}")
            await asyncio.sleep(interval)
import base64
import subprocess
import requests
import time
import os
from typing import Optional, Dict, Any
class Veo3(I2VStrategy):
    
    def generate_video_prompt(self, product, product_info, img_path, img_info, duration: int, action_type: str = "model_show"):
        pass
    
    def generate_video_prompt_with_suggestion(self, product, product_info, img_path, img_info, duration: int, suggestion: str, action_type: str = "model_show"):
        pass
    
    async def execute_generate_video(self, img_path, positive_prompt: str, negative_prompt: str,  duration: int) -> str:
        pass


    def __init__(self, project_id: str, location_id: str = "us-central1", 
                 output_dir: str = "./output", model_id: str = "veo-3.0-generate-preview"):
        name: str = "veo3"

        super().__init__(name)
        """
        åˆå§‹åŒ–è§†é¢‘ç”Ÿæˆå™¨
        
        å‚æ•°:
            project_id (str): Google Cloudé¡¹ç›®ID
            location_id (str): æœåŠ¡ä½ç½®ï¼Œé»˜è®¤ä¸ºus-central1
            output_dir (str): è§†é¢‘ä¿å­˜ç›®å½•ï¼Œé»˜è®¤ä¸º./output
            model_id (str): æ¨¡å‹IDï¼Œé»˜è®¤ä¸ºveo-3.0-generate-preview
        """
        self.project_id = project_id
        self.location_id = location_id
        self.model_id = model_id
        self.api_endpoint = f"{location_id}-aiplatform.googleapis.com"
        
        # åˆ›å»ºè¾“å‡ºç›®å½•
        self.output_dir = output_dir
        os.makedirs(output_dir, exist_ok=True)
        
        print(f"âœ… Veo3VideoGenerator åˆå§‹åŒ–å®Œæˆ")
        print(f"   é¡¹ç›®ID: {project_id}")
        print(f"   æœåŠ¡ä½ç½®: {location_id}")
        print(f"   è¾“å‡ºç›®å½•: {output_dir}")
    
    def _image_to_base64(self, image_path: str) -> str:
        """
        å°†å›¾ç‰‡è½¬æ¢ä¸ºBase64ç¼–ç çš„å­—ç¬¦ä¸²
        
        å‚æ•°:
            image_path (str): å›¾ç‰‡æ–‡ä»¶çš„è·¯å¾„
            
        è¿”å›:
            str: Base64ç¼–ç çš„å›¾ç‰‡å­—ç¬¦ä¸²
        """
        if not os.path.exists(image_path):
            raise FileNotFoundError(f"å›¾ç‰‡æ–‡ä»¶ä¸å­˜åœ¨: {image_path}")
            
        with open(image_path, "rb") as image_file:
            image_data = image_file.read()
            base64_str = base64.b64encode(image_data).decode('utf-8')
            return base64_str
    
    def _get_access_token(self) -> str:
        """
        è·å–Google Cloudè®¿é—®ä»¤ç‰Œ
        
        è¿”å›:
            str: è®¿é—®ä»¤ç‰Œ
        """
        try:
            result = subprocess.run(["gcloud", "auth", "print-access-token"], 
                                  capture_output=True, text=True, check=True)
            return result.stdout.strip()
        except subprocess.CalledProcessError as e:
            raise Exception(f"è·å–è®¿é—®ä»¤ç‰Œå¤±è´¥: {e}")
    
    def _submit_generation_task(self, request_payload: Dict[str, Any]) -> str:
        """
        æäº¤è§†é¢‘ç”Ÿæˆä»»åŠ¡
        
        å‚æ•°:
            request_payload (dict): è¯·æ±‚è½½è·
            
        è¿”å›:
            str: æ“ä½œID
        """
        access_token = self._get_access_token()
        headers = {
            "Content-Type": "application/json",
            "Authorization": f"Bearer {access_token}"
        }
        
        url = f"https://{self.api_endpoint}/v1/projects/{self.project_id}/locations/{self.location_id}/publishers/google/models/{self.model_id}:predictLongRunning"
        
        response = requests.post(url, headers=headers, json=request_payload)
        print(f"æäº¤å“åº”: {response.status_code}")
        
        if response.status_code == 200:
            operation_name = response.json().get("name")
            print(f"âœ… ä»»åŠ¡æäº¤æˆåŠŸï¼Œæ“ä½œID: {operation_name}")
            return operation_name
        else:
            raise Exception(f"æäº¤ä»»åŠ¡å¤±è´¥: {response.text}")
    
    def _fetch_result(self, operation_name: str) -> str:
        """
        è·å–ç”Ÿæˆç»“æœ
        
        å‚æ•°:
            operation_name (str): æ“ä½œID
            
        è¿”å›:
            str: ä¿å­˜çš„è§†é¢‘æ–‡ä»¶è·¯å¾„
        """
        access_token = self._get_access_token()
        headers = {
            "Content-Type": "application/json",
            "Authorization": f"Bearer {access_token}"
        }
        
        fetch_url = f"https://{self.api_endpoint}/v1/projects/{self.project_id}/locations/{self.location_id}/publishers/google/models/{self.model_id}:fetchPredictOperation"
        payload = {"operationName": operation_name}
        
        while True:
            print("ğŸ” æ£€æŸ¥æ“ä½œçŠ¶æ€...")
            response = requests.post(fetch_url, headers=headers, json=payload)
            data = response.json()
            
            if "error" in data:
                raise Exception(f"è§†é¢‘ç”Ÿæˆå¤±è´¥: {data['error']}")
            elif "done" in data and data["done"]:
                print("âœ… è§†é¢‘ç”Ÿæˆå®Œæˆï¼")
                videos = data.get("response", {}).get("videos", [])
                if videos and "bytesBase64Encoded" in videos[0]:
                    video_base64 = videos[0]["bytesBase64Encoded"]
                    filename = f"video_{int(time.time())}.mp4"
                    filepath = os.path.join(self.output_dir, filename)
                    
                    with open(filepath, "wb") as f:
                        f.write(base64.b64decode(video_base64))
                    print(f"ğŸ¬ è§†é¢‘å·²ä¿å­˜ä¸ºï¼š{filepath}")
                    return filepath
                else:
                    raise Exception("æœªæ‰¾åˆ°è§†é¢‘å†…å®¹")
            else:
                print("â³ æ­£åœ¨å¤„ç†ä¸­...")
                time.sleep(30)
    
    def generate_video(self, prompt: str, image_path: Optional[str] = None, 
                      aspect_ratio: str = "16:9", duration_seconds: str = "8",
                      resolution: str = "1080p", generate_audio: bool = True,
                      sample_count: int = 1, add_watermark: bool = False) -> str:
        """
        æ ¸å¿ƒæ–¹æ³•ï¼šç”Ÿæˆè§†é¢‘
        
        å‚æ•°:
            prompt (str): æ–‡æœ¬æç¤ºè¯
            image_path (str, optional): å›¾ç‰‡è·¯å¾„ï¼Œå¦‚æœæä¾›åˆ™è¿›è¡Œå›¾ç‰‡+æ–‡æœ¬ç”Ÿæˆè§†é¢‘
            aspect_ratio (str): å®½é«˜æ¯”ï¼Œé»˜è®¤16:9
            duration_seconds (str): è§†é¢‘æ—¶é•¿ï¼ˆç§’ï¼‰ï¼Œé»˜è®¤8ç§’
            resolution (str): åˆ†è¾¨ç‡ï¼Œé»˜è®¤1080p
            generate_audio (bool): æ˜¯å¦ç”ŸæˆéŸ³é¢‘ï¼Œé»˜è®¤True
            sample_count (int): ç”Ÿæˆæ ·æœ¬æ•°é‡ï¼Œé»˜è®¤1
            add_watermark (bool): æ˜¯å¦æ·»åŠ æ°´å°ï¼Œé»˜è®¤False
            
        è¿”å›:
            str: ç”Ÿæˆçš„è§†é¢‘æ–‡ä»¶è·¯å¾„
        """
        print(f"ğŸ¬ å¼€å§‹ç”Ÿæˆè§†é¢‘...")
        print(f"   æç¤ºè¯: {prompt[:100]}{'...' if len(prompt) > 100 else ''}")
        if image_path:
            print(f"   è¾“å…¥å›¾ç‰‡: {image_path}")
        
        # æ„å»ºè¯·æ±‚å®ä¾‹
        instance = {
            "prompt": prompt
        }
        
        # å¦‚æœæä¾›äº†å›¾ç‰‡è·¯å¾„ï¼Œæ·»åŠ å›¾ç‰‡ä¿¡æ¯
        if image_path:
            pic_base64 = self._image_to_base64(image_path)
            # ä»æ–‡ä»¶æ‰©å±•åæ¨æ–­MIMEç±»å‹
            ext = os.path.splitext(image_path)[1].lower()
            mime_type_map = {
                '.png': 'image/png',
                '.jpg': 'image/jpeg',
                '.jpeg': 'image/jpeg',
                '.webp': 'image/webp'
            }
            mime_type = mime_type_map.get(ext, 'image/png')
            
            instance["image"] = {
                "bytesBase64Encoded": pic_base64,
                "mimeType": mime_type
            }
        
        # æ„å»ºè¯·æ±‚è½½è·
        request_payload = {
            "endpoint": f"projects/{self.project_id}/locations/{self.location_id}/publishers/google/models/{self.model_id}",
            "instances": [instance],
            "parameters": {
                "aspectRatio": aspect_ratio,
                "sampleCount": sample_count,
                "durationSeconds": duration_seconds,
                "personGeneration": "allow_all",
                "addWatermark": add_watermark,
                "includeRaiReason": True,
                "generateAudio": generate_audio,
                "resolution": resolution
            }
        }
        
        # æäº¤ä»»åŠ¡å¹¶è·å–ç»“æœ(å“ªæ€•æŠ¥é”™ä¹Ÿä¸æ–­é‡è¯•ï¼Œä½†æœ€å¤šé‡è¯•3æ¬¡)
        for i in range(3):
            try:
                operation_name = self._submit_generation_task(request_payload)
                video_path = self._fetch_result(operation_name)
                break
            except Exception as e:
                print(f"è§†é¢‘ç”Ÿæˆå¤±è´¥: {e}")
                time.sleep(3)
                continue
        print(f"ğŸ‰ è§†é¢‘ç”Ÿæˆå®Œæˆï¼æ–‡ä»¶è·¯å¾„: {video_path}")
        return video_path

i2v_strategy_chain = I2VStrategyChain([Keling()])

    